{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cfc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf3b74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcda03d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "read the data from the files\n",
    "check if you nead to update path\n",
    "'''\n",
    "EEG_features = pd.read_csv(\"output_b/df_EEG_b_features_Tob_-3_toTob_0.csv\")\n",
    "paymentMethod = pd.read_csv(\"df_painOfPayment_method.csv\")\n",
    "painOfPayment_score = pd.read_csv(\"df_painOfPayment_score.csv\")\n",
    "painOfPayment_score_bins = painOfPayment_score[['subject', 'PainOfPayment_categorical_score']]\n",
    "\n",
    "EEG_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a38ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all():\n",
    "    df_merged = pd.merge(EEG_features, paymentMethod, on=\"subject\", how=\"inner\")\n",
    "    df_merged = pd.merge(df_merged, painOfPayment_score_bins, on=\"subject\", how=\"inner\")\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6e1856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initialize variables\n",
    "'''\n",
    "waves = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "df_data = merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35330cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RandomForest(X_train,y_train):\n",
    "    \n",
    "    # Number of trees in Random Forest\n",
    "    n_estimators = [50, 100, 200, 300]\n",
    "    \n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt', 'log2', None]\n",
    "    \n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(5, 50, 10)]\n",
    "    # Add the default as a possible value\n",
    "    max_depth.append(None)\n",
    "      \n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth':max_depth,\n",
    "                 }\n",
    "    \n",
    "    rf_base = RandomForestClassifier(random_state = 42)\n",
    "    \n",
    "    '''\n",
    "    Create the grid search Random Forest:\n",
    "    GridSearchCV\n",
    "        GridSearch: taking all of paramters combination from the grid parameters to find the best hyper parameters\n",
    "        CV: using cross validation \n",
    "    cv = 4 (4-fold cross validation) --> validation_set = 20% from all data (0.8 X 0.25 = 0.2)\n",
    "    cv = LeaveOneOut()\n",
    "    ''' \n",
    "    rf_search = GridSearchCV(estimator = rf_base, param_grid = param_grid, \n",
    "                               cv = LeaveOneOut(), verbose = 2, n_jobs = -1)\n",
    "    \n",
    "    # Fit the random search model\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5441855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_SVC(X_train, y_train):\n",
    "    \n",
    "    # \n",
    "    C = [0.1,1, 10, 100, 1000]\n",
    "    \n",
    "    # \n",
    "    gamma = [1,0.1,0.01,0.001,0.0001]\n",
    "       \n",
    "    param_grid = {'C': C, 'gamma': gamma}\n",
    "    \n",
    "    SVC_base = SVC(random_state = 42)\n",
    "    \n",
    "    '''\n",
    "    Create the grid search SVC:\n",
    "    GridSearchCV\n",
    "        GridSearch: taking all of paramters combination from the grid parameters to find the best hyper parameters\n",
    "        CV: using cross validation \n",
    "    cv = 4 (4-fold cross validation) --> validation_set = 20% from all data (0.8 X 0.25 = 0.2)\n",
    "    cv = LeaveOneOut()\n",
    "    ''' \n",
    "    \n",
    "    SVC_search = GridSearchCV(estimator = SVC_base, param_grid = param_grid, \n",
    "                               cv = LeaveOneOut(), verbose = 2, n_jobs = -1)\n",
    "    \n",
    "    # Fit the random search model\n",
    "    SVC_search.fit(X_train, y_train)\n",
    "    \n",
    "    return SVC_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e5597bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get model hyperParameters\n",
    "'''\n",
    "def get_hyperParameters(X_train, y_train):\n",
    "    rfc_serach = model_RandomForest(X_train, y_train)\n",
    "    print(rfc_serach.best_params_)\n",
    "\n",
    "    SVC_serach = model_SVC(X_train, y_train)\n",
    "    print(SVC_serach.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ab5a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get model predictions\n",
    "Call predict on the estimator with the best found parameters.\n",
    "'''\n",
    "def get_model_1_predicrions(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # random forest \n",
    "    # using: {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth':Â 15}\n",
    "\n",
    "    rfc = RandomForestClassifier(n_estimators = 200, max_features = 'sqrt', max_depth = 15, random_state = 42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    rfc_predictions = rfc.predict(X_test)\n",
    "    print(confusion_matrix(y_test,rfc_predictions))\n",
    "    print(classification_report(y_test,rfc_predictions))\n",
    "    \n",
    "    rfc_predictions_train = rfc.predict(X_train)\n",
    "    print(confusion_matrix(y_train,rfc_predictions_train))\n",
    "    print(classification_report(y_train,rfc_predictions_train))\n",
    "\n",
    "    # SVM\n",
    "    # using: {'C': 0.1, 'gamma': 1}\n",
    "    svc = SVC(C = 0.1, gamma = 1, random_state = 42)\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    svc_predictions = svc.predict(X_test)\n",
    "    print(confusion_matrix(y_test,svc_predictions))\n",
    "    print(classification_report(y_test,svc_predictions))\n",
    "    \n",
    "    svc_predictions_train = svc.predict(X_train)\n",
    "    print(confusion_matrix(y_train,svc_predictions_train))\n",
    "    print(classification_report(y_train,svc_predictions_train))\n",
    "\n",
    "\n",
    "    # XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "106c9114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "[[2 1 0]\n",
      " [2 3 2]\n",
      " [1 1 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.40      0.67      0.50         3\n",
      " Credit Card       0.60      0.43      0.50         7\n",
      "  Smartphone       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.56      0.59      0.56        16\n",
      "weighted avg       0.59      0.56      0.56        16\n",
      "\n",
      "[[20  0  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       1.00      1.00      1.00        20\n",
      " Credit Card       1.00      1.00      1.00        25\n",
      "  Smartphone       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        62\n",
      "   macro avg       1.00      1.00      1.00        62\n",
      "weighted avg       1.00      1.00      1.00        62\n",
      "\n",
      "[[0 3 0]\n",
      " [0 7 0]\n",
      " [0 6 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00         3\n",
      " Credit Card       0.44      1.00      0.61         7\n",
      "  Smartphone       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.15      0.33      0.20        16\n",
      "weighted avg       0.19      0.44      0.27        16\n",
      "\n",
      "[[ 0 20  0]\n",
      " [ 0 25  0]\n",
      " [ 0 17  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00        20\n",
      " Credit Card       0.40      1.00      0.57        25\n",
      "  Smartphone       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.40        62\n",
      "   macro avg       0.13      0.33      0.19        62\n",
      "weighted avg       0.16      0.40      0.23        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yehuda\\AppData\\Local\\anaconda3\\envs\\my_mne_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MAIN function to get model 1\n",
    "'''\n",
    "# Model 1 (first question): Tries to predict the payment method based on the EEG_features and painOfPayment\n",
    "\n",
    "X = df_data[waves]\n",
    "y = df_data['Payment_method']\n",
    "\n",
    "# test size is 20% from all data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(X_train))\n",
    "\n",
    "\n",
    "# get_hyperParameters(X_train, y_train)\n",
    "# random forest:\n",
    "# cv = 4: {'n_estimators': 200, 'max_features': None, 'max_depth':Â 5}\n",
    "# cv = 5: {'n_estimators': 50, 'max_features': 'sqrt', 'max_depth':Â 5}\n",
    "# cv = LeaveOneOut() : {'n_estimators': 50, 'max_features': 'sqrt', 'max_depth':Â 15} n_estimators = 200 works best\n",
    "\n",
    "# SVC:\n",
    "# cv = 4: {'C': 100, 'gamma': 1}\n",
    "# cv = 5: {'C': 0.1, 'gamma': 1}\n",
    "# cv = LeaveOneOut() : {'C': 0.1, 'gamma': 1}\n",
    "\n",
    "get_model_1_predicrions(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAIN function to get model 2\n",
    "'''\n",
    "# Model 2 (second question) : Tries to predict the painOfPayment score based on the EEG_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAIN function to get model 3\n",
    "'''\n",
    "# Model 3 (thies question) :  Tries to predict the payment amount based on the EEG_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
