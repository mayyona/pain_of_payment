{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cfc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3b74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcda03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read the data from the files\n",
    "check if you nead to update path\n",
    "'''\n",
    "EEG_features = pd.read_csv(\"output_b/df_EEG_b_features_Tob_-3_toTob_0.csv\")\n",
    "paymentMethod = pd.read_csv(\"df_painOfPayment_method.csv\")\n",
    "painOfPayment_score = pd.read_csv(\"df_painOfPayment_score.csv\")\n",
    "painOfPayment_score_bins = painOfPayment_score[['subject', 'PainOfPayment_categorical_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a38ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all():\n",
    "    df_merged = pd.merge(EEG_features, paymentMethod, on=\"subject\", how=\"inner\")\n",
    "    df_merged = pd.merge(df_merged, painOfPayment_score_bins, on=\"subject\", how=\"inner\")\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e1856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "initialize variables\n",
    "'''\n",
    "waves = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "df_data = merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35330cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RandomForest_hyperparameters(X_train,y_train):\n",
    "    \n",
    "    # Number of trees in Random Forest\n",
    "    n_estimators = [50, 100, 200, 300]\n",
    "    \n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt', 'log2', None]\n",
    "    \n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(5, 50, 10)]\n",
    "    # Add the default as a possible value\n",
    "    max_depth.append(None)\n",
    "    \n",
    "    # min_samples_split\n",
    "    min_split = [2,3,4,5]\n",
    "      \n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth':max_depth,\n",
    "                  'min_samples_split': min_split\n",
    "                 }\n",
    "    \n",
    "    rf_base = RandomForestClassifier(random_state = 42)\n",
    "    \n",
    "    '''\n",
    "    Create the grid search Random Forest:\n",
    "    GridSearchCV\n",
    "        GridSearch: taking all of paramters combination from the grid parameters to find the best hyper parameters\n",
    "        CV: using cross validation \n",
    "    cv = 4 (4-fold cross validation) --> validation_set = 20% from all data (0.8 X 0.25 = 0.2)\n",
    "    cv = LeaveOneOut()\n",
    "    ''' \n",
    "    rf_search = GridSearchCV(estimator = rf_base, param_grid = param_grid, \n",
    "                               cv = LeaveOneOut(), verbose = 2, n_jobs = -1)\n",
    "    \n",
    "    # Fit the random search model\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5441855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SVC_hyperparameters(X_train, y_train):\n",
    "    \n",
    "    # \n",
    "    C = [0.1,1, 10, 100, 1000]\n",
    "    \n",
    "    # \n",
    "    gamma = [1,0.1,0.01,0.001,0.0001]\n",
    "       \n",
    "    param_grid = {'C': C, 'gamma': gamma}\n",
    "    \n",
    "    SVC_base = SVC(random_state = 42)\n",
    "    \n",
    "    '''\n",
    "    Create the grid search SVC:\n",
    "    GridSearchCV\n",
    "        GridSearch: taking all of paramters combination from the grid parameters to find the best hyper parameters\n",
    "        CV: using cross validation \n",
    "    cv = 4 (4-fold cross validation) --> validation_set = 20% from all data (0.8 X 0.25 = 0.2)\n",
    "    cv = LeaveOneOut()\n",
    "    ''' \n",
    "    \n",
    "    SVC_search = GridSearchCV(estimator = SVC_base, param_grid = param_grid, \n",
    "                               cv = LeaveOneOut(), verbose = 2, n_jobs = -1)\n",
    "    \n",
    "    # Fit the random search model\n",
    "    SVC_search.fit(X_train, y_train)\n",
    "    \n",
    "    return SVC_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5597bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get model hyperParameters\n",
    "'''\n",
    "def get_hyperParameters(X_train, y_train):\n",
    "    rfc_serach = get_RandomForest_hyperparameters(X_train, y_train)\n",
    "    print(rfc_serach.best_params_)\n",
    "\n",
    "    SVC_serach = get_SVC_hyperparameters(X_train, y_train)\n",
    "    print(SVC_serach.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113f6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrics(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"####### train data results #######\")\n",
    "    train_predictions = model.predict(X_train)\n",
    "    curr_confusion_matrix = confusion_matrix(y_train,train_predictions)\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(curr_confusion_matrix)\n",
    "    curr_classification_report = classification_report(y_train,train_predictions, zero_division=0)\n",
    "    print(\"classification_report: \")\n",
    "    print(curr_classification_report)\n",
    "    print(\"Accuracy: \", model.score(X_train, y_train) , \"\\n\")\n",
    "    \n",
    "    print(\"####### test data results #######\")\n",
    "    test_predictions = model.predict(X_test)\n",
    "    curr_confusion_matrix = confusion_matrix(y_test,test_predictions)\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(curr_confusion_matrix)\n",
    "    curr_classification_report = classification_report(y_test, test_predictions, zero_division=0)\n",
    "    print(\"classification_report: \")\n",
    "    print(curr_classification_report)\n",
    "    print(\"Accuracy: \", model.score(X_test, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4bf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_model(X_train, X_test, y_train, y_test, n_estimators = 200, max_features = 'sqrt', max_depth = 5,  min_samples_split = 5):\n",
    "    print(\"################# RandomForest #################\")\n",
    "   \n",
    "    rfc = RandomForestClassifier(n_estimators = n_estimators, max_features = max_features, max_depth = max_depth,  min_samples_split = min_samples_split, random_state = 42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print_matrics(rfc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5042f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_model(X_train, X_test, y_train, y_test, C = 0.1, gamma = 1):\n",
    "    print(\"################# SVC #################\")\n",
    "    \n",
    "    svc = SVC(C = C, gamma = gamma, random_state = 42)\n",
    "    svc.fit(X_train, y_train) \n",
    "    print_matrics(svc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30cdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_model(X_train, X_test, y_train, y_test):\n",
    "        \n",
    "    print (\"################# DummyClassifier - most_frequent #################\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    print_matrics(dummy_clf, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # \"stratified\" strategy - generates predictions by randomly selecting labels according to the distribution of categories in the training data.\n",
    "    print (\"################# DummyClassifier - stratified #################\")\n",
    "    dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    print_matrics(dummy_clf, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(\"################# LogisticRegression #################\")\n",
    "    Logistic_clf = LogisticRegression(random_state=42)\n",
    "    Logistic_clf.fit(X_train, y_train)\n",
    "    print_matrics(Logistic_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab5a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get model predictions\n",
    "Call predict on the estimator with the best found parameters.\n",
    "'''\n",
    "def get_model_1_predicrions(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # baseline\n",
    "    # Rule-based models\n",
    "    dummy_clf = rule_based_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # random forest \n",
    "    # using: {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth':Â 15, 'min_samples_split': 5}\n",
    "    rfc = RandomForest_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # SVM\n",
    "    # using: {'C': 0.1, 'gamma': 1}\n",
    "    #svc = SVC_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106c9114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# DummyClassifier - most_frequent #################\n",
      "####### train data results #######\n",
      "confusion_matrix: \n",
      "[[ 0 18  0]\n",
      " [ 0 29  0]\n",
      " [ 0 14  0]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00        18\n",
      " Credit Card       0.48      1.00      0.64        29\n",
      "  Smartphone       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.16      0.33      0.21        61\n",
      "weighted avg       0.23      0.48      0.31        61\n",
      "\n",
      "Accuracy:  0.47540983606557374 \n",
      "\n",
      "####### test data results #######\n",
      "confusion_matrix: \n",
      "[[0 5 0]\n",
      " [0 3 0]\n",
      " [0 8 0]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00         5\n",
      " Credit Card       0.19      1.00      0.32         3\n",
      "  Smartphone       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.19        16\n",
      "   macro avg       0.06      0.33      0.11        16\n",
      "weighted avg       0.04      0.19      0.06        16\n",
      "\n",
      "Accuracy:  0.1875 \n",
      "\n",
      "################# DummyClassifier - stratified #################\n",
      "####### train data results #######\n",
      "confusion_matrix: \n",
      "[[ 7  8  3]\n",
      " [ 2 20  7]\n",
      " [10  3  1]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.37      0.39      0.38        18\n",
      " Credit Card       0.65      0.69      0.67        29\n",
      "  Smartphone       0.09      0.07      0.08        14\n",
      "\n",
      "    accuracy                           0.46        61\n",
      "   macro avg       0.37      0.38      0.38        61\n",
      "weighted avg       0.44      0.46      0.45        61\n",
      "\n",
      "Accuracy:  0.45901639344262296 \n",
      "\n",
      "####### test data results #######\n",
      "confusion_matrix: \n",
      "[[2 1 2]\n",
      " [0 3 0]\n",
      " [2 5 1]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.50      0.40      0.44         5\n",
      " Credit Card       0.33      1.00      0.50         3\n",
      "  Smartphone       0.33      0.12      0.18         8\n",
      "\n",
      "    accuracy                           0.38        16\n",
      "   macro avg       0.39      0.51      0.38        16\n",
      "weighted avg       0.39      0.38      0.32        16\n",
      "\n",
      "Accuracy:  0.375 \n",
      "\n",
      "################# LogisticRegression #################\n",
      "####### train data results #######\n",
      "confusion_matrix: \n",
      "[[ 0 18  0]\n",
      " [ 0 29  0]\n",
      " [ 0 14  0]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00        18\n",
      " Credit Card       0.48      1.00      0.64        29\n",
      "  Smartphone       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.16      0.33      0.21        61\n",
      "weighted avg       0.23      0.48      0.31        61\n",
      "\n",
      "Accuracy:  0.47540983606557374 \n",
      "\n",
      "####### test data results #######\n",
      "confusion_matrix: \n",
      "[[0 5 0]\n",
      " [0 3 0]\n",
      " [0 8 0]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.00      0.00      0.00         5\n",
      " Credit Card       0.19      1.00      0.32         3\n",
      "  Smartphone       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.19        16\n",
      "   macro avg       0.06      0.33      0.11        16\n",
      "weighted avg       0.04      0.19      0.06        16\n",
      "\n",
      "Accuracy:  0.1875 \n",
      "\n",
      "################# RandomForest #################\n",
      "####### train data results #######\n",
      "confusion_matrix: \n",
      "[[18  0  0]\n",
      " [ 0 29  0]\n",
      " [ 0  3 11]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       1.00      1.00      1.00        18\n",
      " Credit Card       0.91      1.00      0.95        29\n",
      "  Smartphone       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.95        61\n",
      "   macro avg       0.97      0.93      0.94        61\n",
      "weighted avg       0.96      0.95      0.95        61\n",
      "\n",
      "Accuracy:  0.9508196721311475 \n",
      "\n",
      "####### test data results #######\n",
      "confusion_matrix: \n",
      "[[2 3 0]\n",
      " [1 2 0]\n",
      " [0 6 2]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cash       0.67      0.40      0.50         5\n",
      " Credit Card       0.18      0.67      0.29         3\n",
      "  Smartphone       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.38        16\n",
      "   macro avg       0.62      0.44      0.40        16\n",
      "weighted avg       0.74      0.38      0.41        16\n",
      "\n",
      "Accuracy:  0.375 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MAIN function to get model 1\n",
    "'''\n",
    "# Model 1 (first question): Tries to predict the payment method based on the EEG_features and painOfPayment\n",
    "\n",
    "X = df_data[waves]\n",
    "y = df_data['Payment_method']\n",
    "\n",
    "# test size is 20% from all data\n",
    "# using stratify in order to preserves the relative class proportions in both the training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# get_hyperParameters(X_train, y_train)\n",
    "# random forest:\n",
    "# cv = 4: {'n_estimators': 200, 'max_features': None, 'max_depth':Â 5}\n",
    "# cv = 5: {'n_estimators': 50, 'max_features': 'sqrt', 'max_depth':Â 5}\n",
    "# cv = LeaveOneOut() : {'n_estimators': 50, 'max_features': 'sqrt', 'max_depth':Â 15}\n",
    "\n",
    "# with min_samples_split and cv = 4: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 200}\n",
    "# with min_samples_split and cv = 5: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
    "# with min_samples_split and cv = LeaveOneOut(): {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 200}\n",
    "\n",
    "# random forest - stratify:\n",
    "# with min_samples_split and cv = 4: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 200}\n",
    "# with min_samples_split and cv = 5: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 50}\n",
    "# with min_samples_split and cv = LeaveOneOut(): {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 50}\n",
    "\n",
    "# SVC:\n",
    "# cv = 4: {'C': 100, 'gamma': 1}\n",
    "# cv = 5: {'C': 0.1, 'gamma': 1}\n",
    "# cv = LeaveOneOut() : {'C': 0.1, 'gamma': 1}\n",
    "\n",
    "get_model_1_predicrions(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0b5509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAIN function to get model 2 - classification\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MAIN function to get model 2 - classification\n",
    "'''\n",
    "# Model 2 (second question) : Tries to predict the painOfPayment score based on the EEG_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d211f74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAIN function to get model 3 - regression\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MAIN function to get model 3 - regression\n",
    "'''\n",
    "# Model 3 (second question) : Tries to predict the painOfPayment score based on the EEG_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
